{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter.02 Rosenblatt's Perceptron\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.1 Rosenblatt's Perceptron Model\n",
    "2.1.1. Overview<br>\n",
    "\n",
    "1. The first model/algorithm for supervised learning, in <strong>1957</strong> \n",
    "2. Single-layer single-output neural network for binary classification of <strong>linearly separable</strong> patterns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "2.1.2. Activation function : Sign function(threshold function)\n",
    "\n",
    "$$\n",
    "\\varphi(x) = \n",
    "\\begin{cases}\n",
    "+1, \\quad if \\,\\ x > 0 \\\\\n",
    "-1, \\quad if \\,\\ x < 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "2.1.3. Network Architecture<br>\n",
    "- Basic model :\n",
    "\n",
    "<img src=\"./res/ch02/fig_2_1.png\" width=\"550\" height=\"300\"><br>\n",
    "<p style=\"text-align:center\">Figure.2.1.1</p>\n",
    "\n",
    "- Compact model : \n",
    "\n",
    "$ Let \\,\\ \\mathbf{x} = [+1, \\,\\ x_1, \\,\\ x_2, \\,\\ \\cdots, \\,\\ x_m]^T \\,\\ and \\,\\ \n",
    "\\mathbf{w} = [b, \\,\\ w_1, \\,\\ w_2, \\,\\ \\cdots, \\,\\ w_m]^T$<br>\n",
    "$$ v = \\sum_{i = 0}^{m} w_i x_i = \\mathbf{w}^T \\mathbf{x}, \\quad y = sgn(v) = sgn(\\mathbf{w}^T \\mathbf{x}) $$\n",
    "\n",
    "<img src=\"./res/ch02/fig_2_2.png\" width=\"600\" height=\"300\"><br>\n",
    "<p style=\"text-align:center\">Figure.2.1.1</p>\n",
    "\n",
    "2.1.4. Assumption <br>\n",
    " - This is binary classification.\n",
    " - Two classes are linearly separable.\n",
    " - Decision boundary(Hyper plane) : \n",
    " $$ \\mathbf{w}^T \\mathbf{x} = 0 $$\n",
    " - Decision rule for binary classification :\n",
    " $$ \\mathbf{x} \\in C_1 \\,\\ if \\,\\ y = +1 \\,\\ \\nLeftrightarrow \\,\\ \\mathbf{w}^T \\mathbf{x} > 0 $$\n",
    " $$ \\mathbf{x} \\in C_2 \\,\\ if \\,\\ y = -1 \\,\\ \\nLeftrightarrow \\,\\ \\mathbf{w}^T \\mathbf{x} < 0 $$\n",
    "\n",
    "2.1.5. Training Problem Definition<br>\n",
    "To find a weight vector $ \\mathbf{w} $ such that<br>\n",
    "$ \\mathbf{w}^T \\mathbf{x} > 0 $ for every input vector $ \\mathbf{x} $ belonging to class $ C_1 $<br>\n",
    "$ \\mathbf{w}^T \\mathbf{x} \\le 0 $ for every input vector $ \\mathbf{x} $ belonging to class $ C_2 $<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "2.1.6. Training Algorithm for Perceptron<br>\n",
    "- Cost function : Use distance metric, not MSE. Total Distance between the classifier and misclassified samples.\n",
    "\n",
    "$$ J(\\mathbf{w}) = \\sum_{\\mathbf{x} \\in \\mathcal{H}} | \\mathbf{w}^T \\mathbf{x} |, \\quad where \\,\\ \\mathcal{H} \\text{ is set of misclassfied samples.} $$\n",
    "Therefore, \n",
    "$$ (\\mathbf{w}^T \\mathbf{x}) d > 0  \\quad (\\text{correctly classified}) $$\n",
    "$$ (\\mathbf{w}^T \\mathbf{x}) d \\le 0  \\quad (\\text{wrongly classified}) $$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.2 Perceptron Convergence Theorem\n",
    "\n",
    "### 2.3 Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}