{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alternate-contrary",
   "metadata": {},
   "source": [
    "# Chapter.04 Statistical Learning\n",
    "---\n",
    "All of the regression analysis techniques seen in CH03 depend on the quality and quantity of data. If there is no data and only statistical information, then is it possible to learn? For this, consider applying the Linear Regression technique.<br><br>\n",
    "\n",
    "As we know, I'll use linearly regressive and approximated models in CH03.2.1 with Expectational error; $ \\mathbb{E}[\\epsilon] = 0, \\,\\ \\mathbb{E}[\\epsilon^2] = \\sigma^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-concert",
   "metadata": {},
   "source": [
    "### 4.1. Wiener filter(Optimal linear MMSE filter)\n",
    "4.1.1. Overview<br>\n",
    "Let's consider the linear regression problem\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{w}} \\left\\{ J(\\mathbf{w}) = \\frac{1}{2}|| \\mathbf{y} - X\\mathbf{w} ||^2 \\right\\} \\quad \n",
    "\\text{where} \\,\\ \\mathbf{w} = [b, w_1, w_2, \\cdots]^T, \\,\\ \\mathbf{x} = [1, x_1, x_2, \\cdots]^T, \\,\\ \\mathbf{y} = [y_1, \\cdots, y_N]^T, \\,\\ X = [\\mathbf{x}_1, \\cdots, \\,\\ \\mathbf{x}_N]^T\n",
    "$$\n",
    "\n",
    "The LS solution of above problem is \n",
    "$$ \\mathbf{w} = (X^TX)^{-1}X^T \\mathbf{y} $$\n",
    "Therefore, we can see that the solution depends on the training data $(x, y)$.<br>\n",
    "Let's see what happens if the number of training samples approaches infinity (i.e., $N \\rightarrow \\infty$)\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{w} &= (\\frac{1}{N}X^TX)^{-1}(\\frac{1}{N}X^T\\mathbf{y}) \\\\\n",
    "           &\\rightarrow \\mathbf{w} = R^{-1}_x \\mathbf{r}_{xy} \\\\\n",
    "\\end{align*}   \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{where} \\,\\ &\\frac{1}{N} X^TX = \\frac{1}{N} \\sum_{i = 1}^{N} \\mathbf{x}_i \\mathbf{x}_i^T = \\mathbb{E}[\\mathbf{x}\\mathbf{x}^T] = R_x \\quad \\text{(covariance of input)}, \\\\\n",
    "                 &\\frac{1}{N}X^T\\mathbf{y} = \\frac{1}{N} \\sum_{i = 1}^{N} \\mathbf{x}_iy_i = \\mathbb{E}[\\mathbf{x}y] = \\mathbf{r}_{xy} \\quad \\text{(cross correlation)} \\\\\n",
    "\\end{align*}            \n",
    "$$\n",
    "\n",
    "Now, the solution depends only on the second-order statistics of the training data $ (x, y) $, not the training data itself. If there are so many data so that we cannot learn the system, we can use __Wiener filter__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-crack",
   "metadata": {},
   "source": [
    "4.1.2. Optimal linaer filtering problem<br>\n",
    "This is good for __audio data__. The limiting form of the linear regression problem with infinitely many training samples; \n",
    "\n",
    "$$ \\min_{\\mathbf{w}} \\left\\{ J(\\mathbf{w}) = \\frac{1}{2} \\mathbb{E}\\left[ (y - \\mathbf{w}^T \\mathbf{x})^2 \\right] \\right\\} $$\n",
    "\n",
    ", that is convex and quadratic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-omega",
   "metadata": {},
   "source": [
    "4.1.3. Winer filter(Limiting form of the LS solution)<br>\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{w}_{WF} &= \\arg\\min_{\\mathbf{w}} \\mathbb{E}[(y - \\mathbf{w}^T \\mathbf{x})^2] \\\\\n",
    "                &= R_{x}^{-1} \\mathbf{r}_{xy} \\quad \\text{(optimal linear filtering in the MMSE sense)} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "<strong>Proof.</strong><br>\n",
    "[PDF File too long](./res/ch04/Ch04.3.1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-spirit",
   "metadata": {},
   "source": [
    "### 4.2. Steepest Gradient Descent Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-benjamin",
   "metadata": {},
   "source": [
    "### 4.3. Least Mean Square(LMS) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-emperor",
   "metadata": {},
   "source": [
    "### 4.4. Minimum Mean Square Error(MMSE) Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-victorian",
   "metadata": {},
   "source": [
    "<strong>Reference.</strong><br>\n",
    "https://www.google.com/search?client=safari&rls=en&q=wiener+filter&ie=UTF-8&oe=UTF-8<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
