{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.06 Practical Issues in Machine Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Bias-Variance tradeoff\n",
    "6.1.1. Bias-Variance decomposition of the MSE<br>\n",
    "For any supervised learning algorithm, we can decompose the MSE on an unseen sample $\\mathbf{x}$ as\n",
    "$$ \\mathbb{E}[(y - \\hat{f}(x; D))^2] = (Bias_D[\\hat{f}(x; D)])^2 + Var_D[\\hat{f}(x; D)] + \\sigma^2 $$\n",
    "$$ \\text{where} \\quad Bias_D[\\hat{f}(x;D)] = \\mathbb{E}_D[\\hat{f}(x;D)] - f(x) \\,\\ \\text{and} \\,\\ Var_D[\\hat{f}(x;D)] = \\mathbb{E}_D[(\\mathbb{E}_D[\\hat{f}(x ; D)] - \\hat{f}(x;D))^2 ] $$\n",
    "\n",
    "- $Bias_D[\\hat{f}(x;D)]$ is due to improper model or assumption.(e.g., When approximating a non-linear funcvtion $f(x)$ using a learning method for linear models, there will be error in the estimates $\\hat{f}(x)$ due to this assumption).\n",
    "- $Var_D[\\hat{f}(x;D)]$ is variation of an algorithm itself.\n",
    "- $\\sigma^2$ is inherent noise(irreducible error).<br><br>\n",
    "\n",
    "<strong>Proof.</strong><br>\n",
    "[PDF File too long](./res/ch06/note_bias-variance_tradeoff.pdf)\n",
    "\n",
    "Therefore, \n",
    "$$ \\text{MSE} = \\mathbb{E}_x \\left\\{ Bias_D[\\hat{f}(x;D)]^2 + Var_D[\\hat{f}(x;D)] \\right\\} + \\sigma^2 $$\n",
    "\n",
    "\n",
    "<img src=\"./res/ch06/fig_1_1.png\" width=\"400\" height=\"300\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.1.1\n",
    "</div>\n",
    "\n",
    "\n",
    "- The more complex the model is, the more data points it will capture. $\\rightarrow$ the lower the bias will be.\n",
    "- However, the complexity will make the model vary more to capture the data points $\\rightarrow$ the larger the variance will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Generalization\n",
    "6.2.1. Overview<br>\n",
    "- The ultimate goal of machine learning is __good generalization__.\n",
    "- Data we observed is just a part of the whole.\n",
    "- We need to find a model that well explains the whole data only from a given portion of data.\n",
    "- Good explainability for unobserved data.\n",
    "\n",
    "Generalization depends on __amount of training data__ and __complexity of model__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2.2. Training and test data sets<br>\n",
    "\n",
    "\n",
    "<img src=\"./res/ch06/fig_2_1.png\" width=\"400\" height=\"300\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.2.1\n",
    "</div>\n",
    "\n",
    "- The whole training data is split into two parts: (i) training set and (ii) test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Curse of dimensionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
