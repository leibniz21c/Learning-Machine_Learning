{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.06 Practical Issues in Machine Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Bias-Variance tradeoff\n",
    "6.1.1. Bias-Variance decomposition of the MSE<br>\n",
    "For any supervised learning algorithm, we can decompose the MSE on an unseen sample $\\mathbf{x}$ as\n",
    "$$ \\mathbb{E}[(y - \\hat{f}(x; D))^2] = (Bias_D[\\hat{f}(x; D)])^2 + Var_D[\\hat{f}(x; D)] + \\sigma^2 $$\n",
    "$$ \\text{where} \\quad Bias_D[\\hat{f}(x;D)] = \\mathbb{E}_D[\\hat{f}(x;D)] - f(x) \\,\\ \\text{and} \\,\\ Var_D[\\hat{f}(x;D)] = \\mathbb{E}_D[(\\mathbb{E}_D[\\hat{f}(x ; D)] - \\hat{f}(x;D))^2 ] $$\n",
    "\n",
    "- $Bias_D[\\hat{f}(x;D)]$ is due to improper model or assumption.(e.g., When approximating a non-linear funcvtion $f(x)$ using a learning method for linear models, there will be error in the estimates $\\hat{f}(x)$ due to this assumption).\n",
    "- $Var_D[\\hat{f}(x;D)]$ is variation of an algorithm itself.\n",
    "- $\\sigma^2$ is inherent noise(irreducible error).<br><br>\n",
    "\n",
    "<strong>Proof.</strong><br>\n",
    "[PDF File too long](./res/ch06/note_bias-variance_tradeoff.pdf)\n",
    "\n",
    "Therefore, \n",
    "$$ \\text{MSE} = \\mathbb{E}_x \\left\\{ Bias_D[\\hat{f}(x;D)]^2 + Var_D[\\hat{f}(x;D)] \\right\\} + \\sigma^2 $$\n",
    "\n",
    "\n",
    "<img src=\"./res/ch06/fig_1_1.png\" width=\"400\" height=\"300\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.1.1\n",
    "</div>\n",
    "\n",
    "\n",
    "- The more complex the model is, the more data points it will capture. $\\rightarrow$ the lower the bias will be.\n",
    "- However, the complexity will make the model vary more to capture the data points $\\rightarrow$ the larger the variance will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Generalization\n",
    "6.2.1. Overview<br>\n",
    "- The ultimate goal of machine learning is __good generalization__.\n",
    "- Data we observed is just a part of the whole.\n",
    "- We need to find a model that well explains the whole data only from a given portion of data.\n",
    "- Good explainability for unobserved data.\n",
    "\n",
    "Generalization depends on __amount of training data__ and __complexity of model__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2.2. Training and test data sets<br>\n",
    "\n",
    "\n",
    "<img src=\"./res/ch06/fig_2_1.png\" width=\"400\" height=\"300\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.2.1\n",
    "</div>\n",
    "\n",
    "- The whole training data is split into two parts: (i) training set and (ii) test set\n",
    "- Usually, the training set is used for training model (or a machine learning algorithm)\n",
    "- Whereas, the test set is used to evaluate the (generalization) performance of the model\n",
    "\n",
    "For example, in polynomial curve fitting with training and test sets\n",
    "\n",
    "<img src=\"./res/ch06/fig_2_2.png\" width=\"600\" height=\"300\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.2.2\n",
    "</div>\n",
    "\n",
    "<img src=\"./res/ch06/fig_2_3.png\" width=\"800\" height=\"300\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.2.3\n",
    "</div>\n",
    "\n",
    "In above figure.6.2.3, when $ M = 0 $, it is under-fitting, because $ M $ cannot learn any data because there isn't weight value that can fit.<br>\n",
    "When $ M = 1 $, it is under-fitting, because $ M $ can fit just linear data because there is an only one weight value.<br>\n",
    "When $ M = 3 $, it is well-fitting(best model), because the model is a good representation of the nonlinearity of the data.\n",
    "When $ M = 9 $, it is over-fitting, because $ M $ is too large so that the model memorize lots of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Overfitting\n",
    "So, what is overfitting? It is very __good only for training data__ (memorization). But, it is __not good for test data__ (poor generalization). <br><br>\n",
    "\n",
    "6.3.1. How to avoid overfitting?<br>\n",
    "\n",
    "6.3.1.1. More training data<br>\n",
    "   \n",
    "__Widrow's rule of thumb__ \n",
    "\n",
    "$$\n",
    "N = O \\left( \\frac{W}{\\epsilon} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where} \\,\\ N \\,\\ \\text{is number of training samples,} \\,\\ W \\,\\ \\text{is total number of parameters,} \\,\\ \\epsilon \\,\\ \\text{is fraction of target error.}\n",
    "$$\n",
    "\n",
    "For example, when you set $ \\epsilon $ to $ 10% $, it should be\n",
    "\n",
    "$$\n",
    "\\epsilon = 0.1 \\quad \\rightarrow \\quad N \\ge 10W\n",
    "$$\n",
    "\n",
    "6.3.1.2. Reducing the number of features(e.g., by PCA)<br>\n",
    "\n",
    "We have to find a number of suitable features because if there are so many features, the model can learn noises that hinders generalization, and variation of weights is so high.\n",
    "\n",
    "6.3.1.3. Regularization<br>\n",
    "\n",
    "Regularization is restricting the model complexity. It is based on __Occam's razor__ which means the simple is the best.\n",
    "\n",
    "    - L1-Regularization(CH03.02)\n",
    "    - L2-Regularization(CH03.02)\n",
    "    - Max-Norm Constraint\n",
    "    \n",
    "$$\n",
    "|| \\mathbf{w} ||_\\infty \\le u\n",
    "$$\n",
    "\n",
    "There are two type of weights. First one is weights having significant influence on performance. __Second one have little or no influence so these can cause overfitting.__  We have to restricting those weights to be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3.1.4. Dropout<br>\n",
    "\n",
    "<img src=\"./res/ch06/fig_3_1.png\" width=\"600\" height=\"250\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.3.1\n",
    "</div>\n",
    "\n",
    "Dropout prevents co-adaptations among neurons on training data. Neurons are dropped out with probability $ (1 - p) $ or kept with probability $ p $. Train with reduced (multiple) networks, and then, test with all trained nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3.1.5. Early-stopping<br>\n",
    "When we train some data with out model, we can see a situation like __Figure.6.1.1__. Obiously, we can stop learning early when the total error is minimal during learning. It is called early-stopping.\n",
    "\n",
    "<img src=\"./res/ch06/fig_3_2.png\" width=\"500\" height=\"400\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.3.2\n",
    "</div>\n",
    "\n",
    "It perfroms validation after a certain number of epochs(e.g., every 5 epochs). After the validation, it resumes the training process and checks whether overfitting occurs. If then stop the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3.1.6. Proper model selection<br>\n",
    "We must select the best model before overfitting. Training error decreases as the model complexity increases. Test error first decreases and then increases if the model exceeds a certain complexity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how do we choose the best model?<br><br>\n",
    "\n",
    "6.4.1. Model selection with validation<br>\n",
    "6.4.1.1. Model selection with validation set<br>\n",
    "__Input__ : a training/test/validation data set, a set $ \\Omega $ of model.<br>\n",
    "__Algorithm__ : <br>\n",
    "\n",
    "1. For all models in $ \\Omega $ : <br>\n",
    "    1. Train the model using the training data set<br>\n",
    "    2. Evaluate the performance of the trained model using the validation data set<br>\n",
    "2. Select the model with the highest performance<br>\n",
    "3. Evaluate the performance of the chosen model using the test data set<br>\n",
    "\n",
    "<img src=\"./res/ch06/fig_4_1.png\" width=\"500\" height=\"200\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.4.1\n",
    "</div>\n",
    "\n",
    "In above picture, Validation sets are used to select the best model of hyper parameters and check when to early stop the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4.1.2. Multifold($ K $-fold) Cross-Validation<br>\n",
    "__Input__ : a training/test data set, a set $ \\Omega $ of model, the number $ K $ of groups.<br>\n",
    "__Algorithm__ : <br>\n",
    "\n",
    "1. Divide the training data set into $ K $ groups\n",
    "2. For all models in $ \\Omega $ :\n",
    "    1. For $ i = 1 $ to $ K $ :\n",
    "        1. Train the model using the $ (K - 1) $ groups except for the $ i $th group\n",
    "        2. Evaluate the performance of the trained model using the $ i $th group\n",
    "    2. Average the performance of the $ K $ trained models\n",
    "3. Select the model with the highest average performance\n",
    "4. Evaluate the performance of the chosen model using the test data\n",
    "\n",
    "<img src=\"./res/ch06/fig_4_2.png\" width=\"500\" height=\"200\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.4.2\n",
    "</div>\n",
    "\n",
    "It is useful when the amount of training data is not enough. But, the network has to be trained $ K $ times (excessive computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4.1.3. Bootstrap Model Selection<br>\n",
    "__Input__ : a training/test data set, a set $ \\Omega $ of model, a sampling ratio $ \\rho \\,\\ (0 < \\rho < 1) $, an iteration number $ T $<br>\n",
    "__Algorithm__ : <br>\n",
    "1. For all models in $ \\Omega $ :\n",
    "    1. For $ i = 1 $ to $ T $ :\n",
    "        1. Make a new training set $ S^\\prime $ by randomly picking $ \\rho n $ samples from the original training set $ S $\n",
    "        2. Train the model using the new training set $ S^\\prime $\n",
    "        3. Evaluate the performance of the trained model using the data in $ S - S^\\prime $\n",
    "    2. Average the performance of the $ T $ trained models\n",
    "2. Select the model with the highest average performance\n",
    "3. Evaluate the performance of the chosen model using the test data\n",
    "\n",
    "<img src=\"./res/ch06/fig_4_2.png\" width=\"500\" height=\"200\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.4.2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4.2. Model selection with criteria<br>\n",
    "6.4.2.1. Akaike Information Criterion(AIC)<br>\n",
    "Akaike's Information Criterion (AIC) allows to compare the performance of different statistical models.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{AIC}(k) &= N \\log E_k + 2k \\\\\n",
    "              &= \\ln p(D | \\mathbf{w}) - M \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{where} \\,\\ N \\,\\ \\text{is a number of training samples,} \\,\\ E_k \\,\\ \\text{is a modeling error,} \\,\\ k \\,\\ \\text{is a model order(number of parameters).} \n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4.2.2. Minimum Description Length(MDL) Criterion<br>\n",
    "One of the hypotheses that achieves the best data compression, Occam's razor, is a formal name.\n",
    "It means finding a model that minimizes the overall cost function.\n",
    "\n",
    "$$\n",
    "\\text{MDL}(k) = N \\log E_k + k \\log N\n",
    "$$\n",
    "\n",
    "The MDL converges the true order as $ N \\rightarrow \\infty $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. Curse of dimensionality\n",
    "When training a model from data, the more independent samples the better it trains, whereas the larger the dimension, the more difficult it is and requires more data. It is called __curse of dimensionality__. The density of the same number of data rapidly becomes sparse as the dimension increases. <br><br>\n",
    "\n",
    "For example, in K-NN regression, if we use euclid distance metric, we can face it. So, we can use mahalanobis distance metric that consists of information about densities of data.<br><br>\n",
    "\n",
    "In another example, following are polynomial curve fitting when $ M = 1, 2, 3 $.<br>\n",
    "When $ M = 1 $,\n",
    "\n",
    "$$\n",
    "y(\\mathbf{x}, \\mathbf{w}) = w_0 + \\sum_{i = 1}^{D} w_i x_i\n",
    "$$\n",
    "\n",
    "When $ M = 2 $,\n",
    "\n",
    "$$\n",
    "y(\\mathbf{x}, \\mathbf{w}) = w_0 + \\sum_{i = 1}^{D} w_i x_i + \\sum_{i = 1}^{D} \\sum_{j = 1}^{D} w_{ij} x_i x_j\n",
    "$$\n",
    "\n",
    "When $ M = 3 $,\n",
    "\n",
    "$$\n",
    "y(\\mathbf{x}, \\mathbf{w}) = w_0 + \\sum_{i = 1}^{D} w_i x_i + \\sum_{i = 1}^{D} \\sum_{j = 1}^{D} w_{ij} x_i x_j + \\sum_{i = 1}^{D} \\sum_{j = 1}^{D} \\sum_{k = 1}^{D} w_{ijk} x_i x_j x_k\n",
    "$$\n",
    "\n",
    "Each has $ D, \\,\\ D^2 + D, \\,\\ \\text{and} \\,\\ D^3 + D^2 + D $ parameters. Therefore, we can create following formula.\n",
    "\n",
    "$$\n",
    "\\text{Dimensionality} \\propto D^M\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think with the geometric viewpoint. Consider volume of a D-dimensional sphere with $ r = 1 $ as $ V_D(1) $. <br>\n",
    "At this time, the ratio of the volume of the shell is as follows.\n",
    "\n",
    "$$\n",
    "\\frac{V_D(1) - V_D(1 - e)}{V_D(1)} = 1 - (1 - e)^D \\rightarrow 1 \\quad \\text{as} \\quad D \\rightarrow \\infty\n",
    "$$\n",
    "\n",
    "Therefore, in high dimensional spaces, most of the volume of a sphere is concentrated in a thin shell near the surface. The following is the relationship between $ D $ and $ e $.\n",
    "\n",
    "<img src=\"./res/ch06/fig_5_1.png\" width=\"300\" height=\"300\"><br>\n",
    "<div align=\"center\">\n",
    "  Figure.6.5.1.\n",
    "</div>\n",
    "\n",
    "\n",
    "Not all intuitions developed in low-dimensional spaces will generalize to high-dimensional spaces. Certainly, there exist some techniques that are applicable,\n",
    "effective, and specialized only in higher dimensional spaces, although it is not easy to deal with in high dimensional spaces. (e.g., Kerner trick)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Reference.</strong><br>\n",
    "https://en.wikipedia.org/wiki/File:ML_dataset_training_validation_test_sets.png<br>\n",
    "https://en.wikipedia.org/wiki/Akaike_information_criterion<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
