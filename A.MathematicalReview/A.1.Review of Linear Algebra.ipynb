{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix. Review of Linear Algebra\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition.A.1 Frobenius norm of the matrix\n",
    "$$ \\left \\| \\boldsymbol{\\mathbf{X}} \\right \\|_F = \\sqrt{Tr(X^TX)} = \\sqrt{Tr(XX^T)} = \\sum_{i=1}^{m} \\sum_{j=1}^{n} x_{ij}^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition.A.2 Inner product of vectors\n",
    "Let vectors $\\mathbf{w}$ and $\\mathbf{x}$ be $n\\times 1$ vector.<br>\n",
    "$\\mathbf{w}^T\\mathbf{x}$ is called inner product of vectors.<br>\n",
    "\n",
    "$ \\mathbf{w}^T\\mathbf{x} = $ $ \\begin{bmatrix}\n",
    "w_1 & w_2 & \\cdots & w_n \n",
    "\\end{bmatrix} $ $ \\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n \\\\\n",
    "\\end{bmatrix} = $ $ \\sum_{i=1}^{n} w_ix_i $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition.A.3 Outter product of vectors\n",
    "Let vectors $\\mathbf{w}$ and $\\mathbf{x}$ be $n \\times 1$ vectors.<br>\n",
    "$\\mathbf{x}\\mathbf{w}^T$ is called outter product of vectors.<br>\n",
    "\n",
    "$ \\mathbf{x}\\mathbf{w}^T = $ $ \\begin{bmatrix} \n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n \\\\\n",
    "\\end{bmatrix} $ $ \\begin{bmatrix} w_1 & w_2 & \\cdots & w_n \\end{bmatrix} = $ $ \\begin{bmatrix} \n",
    "x_1\\mathbf{w}^T \\\\\n",
    "x_2\\mathbf{w}^T \\\\\n",
    "\\vdots \\\\\n",
    "x_n\\mathbf{w}^T \\\\\n",
    "\\end{bmatrix} = $ $ \\begin{bmatrix}\n",
    " x_1w_1 & x_1w_2 & \\cdots & x_1w_n \\\\\n",
    " x_2w_1 & x_2w_2 & \\cdots & x_2w_n \\\\\n",
    " \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " x_nw_1 & x_nw_2 & \\cdots & x_nw_n \\\\\n",
    " \\end{bmatrix} $ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition.A.4 Matrix-vector multiplication\n",
    "Let $W \\,\\ : \\,\\ m \\times n$ and $\\mathbf{x} \\,\\ : \\,\\ n \\times 1$<br><br>\n",
    "\n",
    "(1)<br>\n",
    "$ W\\mathbf{x} = $ $ \\begin{bmatrix} \\mathbf{w}_1 & \\mathbf{w}_2 & \\cdots & \\mathbf{w}_n \\end{bmatrix} $ $ \\begin{bmatrix}\n",
    "\\mathbf{x}_1 \\\\\n",
    "\\mathbf{x}_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{x}_n \\\\\n",
    "\\end{bmatrix} = $ $ \\sum_{i=1}^{n} \\mathbf{w}_i\\mathbf{x}_i $ <br><br>\n",
    "\n",
    "(2)<br>\n",
    "$ W\\mathbf{x} = $ $ \\begin{bmatrix}\n",
    "\\bar{\\mathbf{w}_1}^T \\\\\n",
    "\\bar{\\mathbf{w}_2}^T \\\\\n",
    "\\vdots \\\\\n",
    "\\bar{\\mathbf{w}_m}^T \\\\\n",
    "\\end{bmatrix} $ $ \\mathbf{x} = $ $ \\begin{bmatrix}\n",
    "\\bar{\\mathbf{w}_1}^T\\mathbf{x} \\\\\n",
    "\\bar{\\mathbf{w}_2}^T\\mathbf{x} \\\\\n",
    "\\vdots \\\\\n",
    "\\bar{\\mathbf{w}_m}^T\\mathbf{x} \\\\\n",
    "\\end{bmatrix} = $ $ \\begin{bmatrix}\n",
    "\\sum_{i=1}^{n} w_{1i}x_i \\\\\n",
    "\\sum_{i=1}^{n} w_{2i}x_i \\\\\n",
    "\\vdots \\\\\n",
    "\\sum_{i=1}^{n} w_{mi}x_i \\\\\n",
    "\\end{bmatrix} $ where $ \\bar{\\mathbf{w}_i} = $ (transpose of i-th row vector of $W$)<br><br>\n",
    "\n",
    "(3)<br>\n",
    "$ W\\mathbf{x} = $ $ \\begin{bmatrix} W_1 & W_2 & \\cdots & W_N \\end{bmatrix} $ $ \\begin{bmatrix}\n",
    "\\mathbf{x}_1 \\\\\n",
    "\\mathbf{x}_2 \\\\\n",
    "\\cdots \\\\\n",
    "\\mathbf{x}_N \\\\\n",
    "\\end{bmatrix} = $ $ \\sum_{i=1}^{N} W_i\\mathbf{x}_i $ where $ \\sum_{i=1}^{N} n_i = n $<br><br>\n",
    "\n",
    "(4)<br>\n",
    "$ W\\mathbf{x} = $ $ \\begin{bmatrix}\n",
    "\\bar{W_1}^T \\\\\n",
    "\\bar{W_2}^T \\\\\n",
    "\\vdots \\\\\n",
    "\\bar{W_M}^T \\\\\n",
    "\\end{bmatrix} $ $ \\mathbf{x} = $ $ \\begin{bmatrix}\n",
    "\\bar{W_1}^T\\mathbf{x} \\\\\n",
    "\\bar{W_2}^T\\mathbf{x} \\\\\n",
    "\\vdots \\\\\n",
    "\\bar{W_M}^T\\mathbf{x} \\\\\n",
    "\\end{bmatrix} $ where $ \\sum_{i=1}^{M} m_i = m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> < Note > </strong><br>\n",
    "(1) : W를 행벡터로 보는 시각 -> 내적의 확장<br>\n",
    "    , 각 bold(x) 인덱스의 w_i 만큼 스칼라배 한다는 관점.<br>\n",
    "(2) : W를 열벡터로 보는 시각 -> 외적의 확장<br>\n",
    "    , 이후 각 원소가 bold(x)만큼의 스칼라배 한다는 관점, 이후 내적으로 변환<br>\n",
    "(3) : 행렬을 서브메트릭스로 나누는 관점 + 벡터를 서브 벡터로 나누는 관점<br>\n",
    "(4) : 파티션하여 다시 벡터를 스칼라로 보고 스칼라배하는 관점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Reference :</strong><br>\n",
    "Deep Learning - Yosha Benjio<br>\n",
    "proofwiki.org\n",
    "wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}