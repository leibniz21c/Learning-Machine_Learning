# Learning-Machine_Learning
---
0. Appendix. Mathematical review
    1. Linear Algebra
    2. Optimization Theory
    3. Probability Theory
    4. Information Theory
    5. Calculus of Variations
1. Artificial Neurons and Neural Networks
    1. Artificial Neurons
    2. Activation functions
    3. Stochastic artificial neuron
    4. Neural Network Architectures
2. Rosenblatt's Perceptron
    1. Rosenblatt's Perceptron Model
    2. Perceptron Convergence Theorem
3. Regression
    1. Regressive and approximated models
        1. General regressive model
    2. Linear Regression
        1. Linearly approximated model
        2. Hypothesis
        3. Linear regression problem
        4. Learning algorithm : A numerical approach
        5. Learning algorithm : Least squares(One-shot learning approach)
        6. Recursive least squares
        7. Regularized least squares
        8. Comparisons
        9. Linear regression with basis functions
        10. Proper step size
        11. Good training samples
    3. Bayesian Regression
        1. Overview
        2. Maximum A Posteriori(MAP) estimation
        3. Maximum Likelihood(ML) estimation
        4. Bayesian linear regression with ML estimation
        5. Bayesian linear regression with MAP estimation
    4. Logistic and Softmax regression
        1. Logistic regression : hypothesis
        2. Logistic regression : learning based on gradient ascent algorithm
        3. Logistic regression : learning via Iterative Reweighted Least Squares(IRLS) based on Newton-Rapson method
        4. Logistic regression : Binary classification
        5. Softmax regression : Overview
        6. Softmax regression : Hypothesis
        7. Softmax regression : Derivative of softmax function
        8. Softmax regression : learning based on gradient ascent algorithm
        9. Softmax regression : learning via Iterative Reweighted Least Squares(IRLS) based on Newton-Rapson method
        10. Softmax regression : Multi-Class classification via softmax regression
    5. k-Nearest Neighbors(k-NN) Regression
        1. ùëò-NN regression
        2.  ùëò-NN classfication
4. Statistical learning
    1. Wiener filter(Optimal linear MMSE filter)
        1. Overview
        2. Optimal linaer filtering problem
        3. Wiener filter(Limiting form of the LS solution)
    2. Steepest Gradient Descent Method and Least Mean Square Algorithm
        1. Gradient descent algorithm
        2. Two approaches for gradient descent
    3. Minimum Mean Square Error(MMSE) Estimator
    4. Review
5. Classification
    1. Definition of classification problem
    2. Linear Models for Classfication
        1. Linear discriminant for two classes
        2. Linear discriminant for multiple classes
        3. Linear models for classification
            1. Linear model for classification : Least squares for classification
            2. Linear model for classification : Fisher's linear discriminant
            3. Linear model for classification : Perceptron
    3. Probabilistic Approaches for Classification
        1. Statistics vs Bayesian Classification
        2. Probabilities in classification
        3. A simple binary classification
        4. Receiver Operating Characteristics (ROC)
        5. Bayesian classification : Minimum Bayes Risk Classifier for two classes
        6. Minimum Error Probability Classifier for two classes
        7. Bayesian classification : Minimum Bayes Risk Classifier for multiple classes
        8. Minimum Error Probability Classifier for multiple classes
        9. Naive Bayes classifier
        10. Assumptions of Naive Bayes classifier
6. Multilayer perceptron

7. Support Vector Machine

8. Restricted Bolzmamn Machines

9. Unsupervised learning

