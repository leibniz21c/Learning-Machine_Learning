{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Appendix.02 Review of Optimization Theory\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Definition.A.2.1 Optimization Problem in general programming\n",
    "Let $ f(\\mathbf{x}) \\,\\ : \\,\\ \\mathbb{R}^n \\rightarrow \\mathbb{R} $ called an object or cost function, <br>\n",
    "$ g_i(\\mathbf{x}) \\,\\ : \\,\\ \\mathbb{R}^n \\rightarrow \\mathbb{R} $ called an inequality constraint function, and <br>\n",
    "$ h_j(\\mathbf{x}) \\,\\ : \\,\\ \\mathbb{R}^n \\rightarrow \\mathbb{R} $ called an equality constraint function be.<br>\n",
    "The following nonlinear programming is called a optimization probelm.\n",
    "$$  \\underset{\\mathbf{x}} \\min \\,\\ f(\\mathbf{x}) \\,\\ s.t. \\,\\ g_i(\\mathbf{x}) \\le 0, \\,\\ i=1,2,\\cdots,m , \\,\\ h_j(\\mathbf{x}) = 0, \\,\\ j=1,2,\\cdots,k.$$\n",
    "$g_i(\\mathbf{x}) \\le 0$ is called an inequlity constraint and $h_j(\\mathbf{x}) = 0$ is called an equality constraint.<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Definition.A.2.2 Lagrangian function\n",
    "In a optimization problem, \n",
    "$$ \\mathcal{L}(\\mathbf{x}, \\mathbf{\\lambda}, \\mathbf{\\mu}) = f(\\mathbf{x}) + \\sum_{i = 1}^{m} \\lambda_i g_i(\\mathbf{x}) + \\sum_{j = 1}^{k} \\mu_j h_j(\\mathbf{x}) \\,\\ where \\,\\ \\mathbf{\\lambda} \\,\\ : \\,\\ m \\times 1, \\,\\ \\mathbf{\\mu} \\,\\ : \\,\\ k \\times 1 $$\n",
    "$ \\lambda_i $ and $ \\mu_i $ are also called dual variables or weights. $ \\mathbf{x} $ is called a primal variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Theorem.A.2.1 Karush-Kuhn-Tucker(KKT) conditions\n",
    "If $ \\mathbf{x}^* \\in \\mathbb{R}^n $ is a local minimum, <br>\n",
    "then $ \\exists \\mathbf{\\lambda}^* \\in \\mathbb{R}^m \\,\\ and \\,\\ \\mathbf{\\mu}^* \\in \\mathbb{R}^k \\,\\ s.t $<br>\n",
    "$ (i) $ Stationarity : <br>\n",
    "$$ \\bigtriangledown f(\\mathbf{x}) + \\sum_i \\lambda_i \\bigtriangledown g_i(\\mathbf{x}) + \\sum_j \\mu_j h_j(\\mathbf{x}) = \\bigtriangledown_\\mathbf{x} \\mathcal{L}(\\mathbf{x}, \\mathbf{\\lambda}, \\mathbf{\\mu}) = \\mathbf{0} $$\n",
    "$ (ii) $ Primal feasibility : <br>\n",
    "$$ g_i(\\mathbf{x}^*) \\le 0, \\,\\ {}_{}^{\\forall}i, \\,\\ h_j(\\mathbf{x}^*) = \\mathbf{0}, \\,\\ {}_{}^{\\forall}j $$\n",
    "$ (iii) $ Dual feasibility : <br>\n",
    "$$ \\lambda_i^* \\ge 0, \\,\\ i=1,\\cdots,m $$\n",
    "$ (vi) $ Complementary slackness : <br>\n",
    "$$ \\lambda_i^* g_i(\\mathbf{x}^*) = 0, \\,\\ i = 1, \\cdots , m $$\n",
    "This $ \\mathbf{x}^* $ is also called a local solution of a optimization problem. KKT Conditions are necessary(not sufficient) for global optimality.<br>\n",
    "$$ \\mathbf{x}^*(\\text{Satisfying the KKT Conditions)} \\,\\ \\leftarrow \\text{Global optimal} $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "라그랑지 함수만들고, KKT-Conditions에 대해서 연립 풀면 x^*가 ㅣocal optimum <br>\n",
    "추가로 convex optimization 이면 Global 보장"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Definition.A.2.3 Convex function\n",
    "A function $ f(\\mathbf{x}) $ is said to be convex if \n",
    "$$ {}_{}^{\\forall}t \\in [0, 1], \\,\\ f(t\\mathbf{x}_1 + (1-t)\\mathbf{x}_2) \\le tf(\\mathbf{x}_1) + (1-t)f(\\mathbf{x}_2), \\,\\ {}_{}^{\\forall}\\mathbf{x}_1, \\mathbf{x}_2 \\in D $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Definition.A.2.4 Convex set\n",
    "A set $S$ is said to be convex if \n",
    "$$ \\mathbf{x}, \\mathbf{y} \\in S \\,\\ \\rightarrow \\,\\ t\\mathbf{x} + (1-t)\\mathbf{y} \\in S, \\,\\ t \\in [0,1] $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Definition.A.2.5 Convex optimization\n",
    "Let $f(\\mathbf{x}) \\,\\ : \\,\\ \\mathbb{R}^n \\rightarrow \\mathbb{R} $ and $ \\mathbf{g}(\\mathbf{x}) \\,\\ : \\,\\ \\mathbb{R}^n \\rightarrow \\mathbb{R}^m $ be convex functions and $ \\mathbf{h}(\\mathbf{x}) \\,\\ : \\,\\ \\mathbb{R}^n \\rightarrow \\mathbb{R}^k $ be an affine function. <br>\n",
    "An optimization problem is called convex if \n",
    "$$ \\underset{\\mathbf{x}} \\min f(\\mathbf{x})  \\quad s.t. \\quad g_i(\\mathbf{x}) \\le 0, \\,\\ i = 1, \\cdots, m, \\quad h_j(\\mathbf{x}) = 0, \\,\\ j = 1, \\cdots, k. $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Affine 함수 : 내적공간 + bias"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Theorem.A.2.2 KKT Conditions in convex problems\n",
    "For convex problem, KKT conditions becomes necessary and also sufficient for global optimality.<br>\n",
    "$(i)$ Stationarity : <br>\n",
    "$$ \\bigtriangledown f(\\mathbf{x}^*) + \\bigtriangledown (\\mathbf{\\lambda}^{*T} \\mathbf{h}(\\mathbf{x}^*)) + \\bigtriangledown (\\mathbf{\\mu}^{*T} \\mathbf{g}(\\mathbf{x}^*) ) = 0 $$\n",
    "$(ii)$ Primal feasibility : <br>\n",
    "$$ \\mathbf{g}(x^*) \\le \\mathbf{0}, \\,\\ \\mathbf{h}(\\mathbf{x^*}) = 0 $$\n",
    "$(iii)$ Dual feasibility : <br>\n",
    "$$ \\mathbf{\\lambda^*} \\ge 0 $$\n",
    "$(vi)$ Complementary slackness : <br>\n",
    "$$ \\mathbf{\\lambda}^{*T} \\mathbf{g}(\\mathbf{x^*}) = 0 $$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Optimal을 찾는다는 관점에서 특정함수를 convex하게 reshape 하는 것을 고려해보자."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Definition.A.2.6 Lagrange dual function\n",
    "$ \\begin{matrix}\n",
    "\\mathcal{D}(\\mathbf{\\lambda}, \\mathbf{\\mu}) &=& \\underset{\\mathbf{x} \\in \\mathcal{X}} \\min \\mathcal{L}(\\mathbf{x}, \\mathbf{\\lambda}, \\mathbf{\\mu}) \\\\\n",
    "&=& \\underset{\\mathbf{x} \\in \\mathcal{X}} \\min \\{ f(\\mathbf{x}) + \\mathbf{\\lambda}^T \\mathbf{h}(\\mathbf{x}) + \\mathbf{\\mu}^T \\mathbf{g}(\\mathbf{x}) \\} \\\\\n",
    "\\text{where} \\quad \\mathcal{X} = \\{ \\mathbf{x} : \\mathbf{g}(\\mathbf{x}) \\le \\mathbf{0}, \\,\\ \\mathbf{h}(\\mathbf{x}) = \\mathbf{0} \\}\n",
    "\\end{matrix} $"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "즉, bold(x)에 대해서 최적화를 진행한 라그랑주 함수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Definition.A.2.7 Lagrange dual problem\n",
    "$ \\underset{\\mathbf{\\lambda} \\ge 0, \\mu} \\max \\mathcal{D} (\\mathbf{\\lambda}, \\mathbf{\\mu}) $<br>\n",
    "$ = \\underset{\\mathbf{\\lambda} \\ge 0, \\mu} \\max \\underset{\\mathbf{x} \\in \\mathcal{X}} \\min \\mathcal{L} (\\mathbf{x}, \\mathbf{\\lambda}, \\mathbf{\\mu}) $<br>\n",
    "$ = \\underset{\\mathbf{\\lambda} \\ge 0, \\mu} \\max \\underset{\\mathbf{x} \\in \\mathcal{X}} \\min \\{ f(\\mathbf{x}) + \\mathbf{\\lambda}^T \\mathbf{g}(\\mathbf{x}) + \\mathbf{\\mu}^T \\mathbf{h}(\\mathbf{x}) \\} $"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Lagrange dual function을 람다, 뮤에 대해서 모두 최적화 해버린 과정"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Theorem.A.2.3 Optimization-theoretic solution of distance between a vector and a hyperplane\n",
    "Let a vector $ \\mathbf{x}_0 $ and a hyperplane $ \\mathbf{w}^T \\mathbf{x} + b = 0 $ be.\n",
    "$$ \\underset{\\mathbf{x}}{\\min } \\left \\| \\mathbf{x}_0 - \\mathbf{x} \\right \\|^2 \\,\\ s.t. \\,\\ \\mathbf{w}^t \\mathbf{x} + b = 0 $$\n",
    "$$ \\therefore \\left \\| \\mathbf{x}_0 - \\mathbf{x}^*  \\right \\|^2 = \\frac{ ( \\mathbf{w}^T \\mathbf{x}_0 + b )^2 }{ \\left \\| \\mathbf{w} \\right \\| } $$<br>\n",
    "\n",
    "<strong>Proof)</strong><br>\n",
    "Let the function $\\mathcal{L} (\\mathbf{x}, \\mathbf{\\lambda}, \\mathbf{\\mu}) = \\left \\| \\mathbf{x}_0 - \\mathbf{x} \\right \\|^2 + \\mu(\\mathbf{w}^T \\mathbf{x} + b) $<br>\n",
    "$ (i) $ <br>\n",
    "$$ \\bigtriangledown_\\mathbf{x} \\mathcal{L} = 2( \\mathbf{x}_0 - \\mathbf{x}^* ) + \\mu \\mathbf{w} = \\mathbf{0} $$\n",
    "$$ 2 \\mathbf{w}^T (\\mathbf{x}_0 - \\mathbf{x}^*) = - \\mu \\left \\| \\mathbf{w} \\right \\|^2 \\quad ( \\because \\,\\ inner \\,\\ product \\,\\ with \\,\\ (\\mathbf{x}_0 - \\mathbf{x}^*) ) $$\n",
    "$$ 2\\left \\| \\mathbf{x}_0 - \\mathbf{x}^* \\right \\|^2 = \\frac{2( \\mathbf{w}^T ( \\mathbf{x}_0 - \\mathbf{x}^* ))^2 }{\\left \\| \\mathbf{w} \\right \\|^2} $$\n",
    "$$ \\therefore \\left \\| \\mathbf{x}_0 - \\mathbf{x}^* \\right \\|^2 = \\frac{ \\{ \\mathbf{w}^T ( \\mathbf{x}_0 - \\mathbf{x}^* )\\}^2 }{\\left \\| \\mathbf{w} \\right \\|^2}  $$\n",
    "\n",
    "$ \\blacksquare $"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Constraint가 있는 문제들은 이때까지 방식으로 처리."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Theorem.A.2.4 Gradient descent method\n",
    "Gradient descent is an iterative method to find a stationary point of an unconstraint optimization problem : <br>\n",
    "$$ \\underset{\\mathbf{\\theta}} \\min L (\\mathbf{\\theta}) $$\n",
    "$$ L(\\mathbf{\\theta} + \\eta \\mathbf{d}) \\approx L(\\mathbf{\\theta}) + \\eta \\bigtriangledown  _\\mathbf{\\theta} ^ T L( \\mathbf{\\theta} ) \\mathbf{d} \\quad where \\quad \\eta > 0, \\,\\  \\left \\| \\mathbf{d}  \\right \\| = 1 $$\n",
    "$$L(\\mathbf{\\theta} + \\eta \\mathbf{d}) - L(\\mathbf{\\theta}) \\approx \\eta \\bigtriangledown  _\\mathbf{\\theta} ^ T L( \\mathbf{\\theta} ) \\mathbf{d} = \\eta \\cos{(\\phi)} \\left \\| \\bigtriangledown  _\\mathbf{\\theta} ^ T L( \\mathbf{\\theta} ) \\right \\| $$<br>\n",
    "\n",
    "Find the directional vector $\\mathbf{d}$ that minimizes $ L(\\mathbf{\\theta} + \\eta \\mathbf{d} ) - L(\\mathbf{\\theta}) \\le 0 $<br>\n",
    "$$ \\cos{(\\phi)} = -1 \\,\\ \\rightarrow \\,\\ \\mathbf{d} = - \\frac{\\bigtriangledown_\\mathbf{\\theta} L( \\mathbf{\\theta} ) }{ \\left \\| \\bigtriangledown  _\\mathbf{\\theta} L( \\mathbf{\\theta} ) \\right \\| } $$\n",
    "$$ \\therefore \\mathbf{\\theta} + \\eta \\mathbf{d} = \\mathbf{\\theta} - \\eta \\frac{\\bigtriangledown_\\mathbf{\\theta} L( \\mathbf{\\theta} ) }{ \\left \\| \\bigtriangledown  _\\mathbf{\\theta} L( \\mathbf{\\theta} ) \\right \\| } = \\mathbf{\\theta} - \\alpha \\bigtriangledown_\\mathbf{\\theta} L( \\mathbf{\\theta} ) $$\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Theorem.A.2.4 Types of gradient descent method\n",
    "$ (i) \\,\\ \\text{Standard (or steepest) Gradient Descent} $\n",
    "$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\bigtriangledown \\mathbb{E}[J(\\mathbf{w})] $$\n",
    " - Practically infeasible\n",
    " - Thus, we need distribution about data $\\mathbf{x}$ (Contradiction)\n",
    " - So, We can use sample mean\n",
    "<br><br>\n",
    "\n",
    "$ (ii) \\,\\ \\text{Stochastic Gradient Descent} $\n",
    "$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\bigtriangledown J_i(\\mathbf{w}) $$\n",
    " - Simple to implement \n",
    " - Effective for large-scale problem\n",
    " - Much less memory\n",
    " - Unstable : zigzaging\n",
    " - 취지 : We just consider one of data. Just one.\n",
    " - It can be convergent. But there is little unstable.\n",
    "<br><br>\n",
    "\n",
    "$ (iii) \\,\\ \\text{Batch gradient Descent} $\n",
    "$$ \\mathbf{w} \\leftarrow \\eta \\bigtriangledown \\sum_{i=1}^{N} J_i (\\mathbf{w}) $$\n",
    " - Accurate estimation of gradients\n",
    " - Parallelization of learning\n",
    " - Large memory\n",
    " - Big time-complexity can be problem in this method.(So slow)\n",
    " - But, there isn't problem in convergence. \n",
    " - 취지 : We consider all of data!\n",
    "<br><br>\n",
    "\n",
    "$ (vi) \\,\\ \\text{Mini-Batch Gradient Descent} $\n",
    "$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\bigtriangledown \\sum_{i \\in \\mathfrak{I}}^{N} J_i (\\mathbf{w}), \\quad 1 \\le \\left | \\mathfrak{I} \\right | \\le N $$\n",
    " - Most generalized version\n",
    " - Effective to deal with large\n",
    " - Amount of training data\n",
    " - 취지 : We just consider seveal datas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<strong>Reference :</strong><br>\n",
    "Deep Learning - Yosha Benjio<br>\n",
    "Neural networks and learning machines - Simon Haykin<br>\n",
    "https://wikipedia.org<br>\n",
    "https://ko.wikipedia.org/wiki/위키백과:TeX_문법<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}